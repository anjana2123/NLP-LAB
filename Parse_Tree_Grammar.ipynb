{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a764e0c8-652a-4d79-93b8-636fba527c0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk.parse.dependency'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DependencyGraph\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_pos_tags\u001b[39m(sentence):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk.parse.dependency'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from nltk.parse.dependency import DependencyGraph\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def get_pos_tags(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    return pos_tags\n",
    "\n",
    "def visualize_dependency(sentence):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    # Visualize the dependency tree\n",
    "    from spacy import displacy\n",
    "    displacy.render(doc, style=\"dep\", jupyter=True)\n",
    "\n",
    "def dependency_parse(sentence):\n",
    "    # Bottom-up dependency parsing\n",
    "    pos_tags = get_pos_tags(sentence)\n",
    "    dg = DependencyGraph(pos_tags)\n",
    "    bottom_up_tree = dg.triples()\n",
    "\n",
    "    # Top-down dependency parsing\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(sentence)\n",
    "    top_down_tree = [(token.text, token.head.text, token.dep_) for token in doc]\n",
    "\n",
    "    return bottom_up_tree, top_down_tree\n",
    "\n",
    "def predict_grammatical_correctness(sentence):\n",
    "    # Preprocess the input sentence\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    features = [len(tokens), len(set(tokens)), sum(len(word) for word in tokens)]\n",
    "\n",
    "    # Train a logistic regression model\n",
    "    X_train = [[5, 5, 20], [10, 8, 50], [3, 3, 15], [7, 6, 35]]  # Example training data\n",
    "    y_train = [1, 1, 0, 1]  # Example labels (1 for grammatically correct, 0 for incorrect)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make a prediction on the input sentence\n",
    "    X_test = [features]\n",
    "    prediction = model.predict(X_test)[0]\n",
    "\n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "input_sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# POS tagging\n",
    "pos_tags = get_pos_tags(input_sentence)\n",
    "print(\"POS Tags:\", pos_tags)\n",
    "\n",
    "# Dependency parsing\n",
    "bottom_up_tree, top_down_tree = dependency_parse(input_sentence)\n",
    "print(\"Bottom-up Dependency Tree:\", bottom_up_tree)\n",
    "print(\"Top-down Dependency Tree:\", top_down_tree)\n",
    "visualize_dependency(input_sentence)\n",
    "\n",
    "# Grammatical correctness prediction\n",
    "grammatical_correctness = predict_grammatical_correctness(input_sentence)\n",
    "print(\"Grammatical Correctness:\", \"Correct\" if grammatical_correctness == 1 else \"Incorrect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03c63dec-a627-4a24-8f24-3c00f5371229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\anjan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\anjan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63488b58-3732-48e4-99ed-74c9a2825e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: [('The', 'DET'), ('quick', 'ADJ'), ('brown', 'ADJ'), ('fox', 'NOUN'), ('jumps', 'VERB'), ('it', 'PRON'), ('on', 'ADP'), ('the', 'DET'), ('lazy', 'ADJ'), ('dog', 'NOUN'), ('.', 'PUNCT')]\n",
      "Dependency Tree: [('The', 'fox', 'det'), ('quick', 'fox', 'amod'), ('brown', 'fox', 'amod'), ('fox', 'jumps', 'nsubj'), ('jumps', 'jumps', 'ROOT'), ('it', 'jumps', 'dobj'), ('on', 'jumps', 'prep'), ('the', 'dog', 'det'), ('lazy', 'dog', 'amod'), ('dog', 'on', 'pobj'), ('.', 'jumps', 'punct')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"aca7f3b354834dee9a2a35e51cf01350-0\" class=\"displacy\" width=\"1800\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">quick</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">brown</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">fox</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">jumps</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">it</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">on</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">lazy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">dog.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aca7f3b354834dee9a2a35e51cf01350-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,2.0 575.0,2.0 575.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aca7f3b354834dee9a2a35e51cf01350-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aca7f3b354834dee9a2a35e51cf01350-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aca7f3b354834dee9a2a35e51cf01350-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aca7f3b354834dee9a2a35e51cf01350-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aca7f3b354834dee9a2a35e51cf01350-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aca7f3b354834dee9a2a35e51cf01350-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aca7f3b354834dee9a2a35e51cf01350-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aca7f3b354834dee9a2a35e51cf01350-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aca7f3b354834dee9a2a35e51cf01350-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,266.5 L923.0,254.5 907.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aca7f3b354834dee9a2a35e51cf01350-0-5\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aca7f3b354834dee9a2a35e51cf01350-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1095.0,266.5 L1103.0,254.5 1087.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aca7f3b354834dee9a2a35e51cf01350-0-6\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,89.5 1620.0,89.5 1620.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aca7f3b354834dee9a2a35e51cf01350-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aca7f3b354834dee9a2a35e51cf01350-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,177.0 1615.0,177.0 1615.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aca7f3b354834dee9a2a35e51cf01350-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-aca7f3b354834dee9a2a35e51cf01350-0-8\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,2.0 1625.0,2.0 1625.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-aca7f3b354834dee9a2a35e51cf01350-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1625.0,266.5 L1633.0,254.5 1617.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammatical Correctness: Correct\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def get_pos_tags(sentence):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(sentence)\n",
    "    pos_tags = [(token.text, token.pos_) for token in doc]\n",
    "    return pos_tags\n",
    "\n",
    "def visualize_dependency(sentence):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    # Visualize the dependency tree\n",
    "    from spacy import displacy\n",
    "    displacy.render(doc, style=\"dep\", jupyter=True)\n",
    "\n",
    "def dependency_parse(sentence):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(sentence)\n",
    "    dependency_tree = [(token.text, token.head.text, token.dep_) for token in doc]\n",
    "    return dependency_tree\n",
    "\n",
    "def predict_grammatical_correctness(sentence):\n",
    "    # Preprocess the input sentence\n",
    "    tokens = sentence.split()\n",
    "    features = [len(tokens), len(set(tokens)), sum(len(word) for word in tokens)]\n",
    "\n",
    "    # Train a logistic regression model\n",
    "    X_train = [[5, 5, 20], [10, 8, 50], [3, 3, 15], [7, 6, 35]]  # Example training data\n",
    "    y_train = [1, 1, 0, 1]  # Example labels (1 for grammatically correct, 0 for incorrect)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make a prediction on the input sentence\n",
    "    X_test = [features]\n",
    "    prediction = model.predict(X_test)[0]\n",
    "\n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "input_sentence = \"The quick brown fox jumps it on the lazy dog.\"\n",
    "\n",
    "# POS tagging\n",
    "pos_tags = get_pos_tags(input_sentence)\n",
    "print(\"POS Tags:\", pos_tags)\n",
    "\n",
    "# Dependency parsing\n",
    "dependency_tree = dependency_parse(input_sentence)\n",
    "print(\"Dependency Tree:\", dependency_tree)\n",
    "visualize_dependency(input_sentence)\n",
    "\n",
    "# Grammatical correctness prediction\n",
    "grammatical_correctness = predict_grammatical_correctness(input_sentence)\n",
    "print(\"Grammatical Correctness:\", \"Correct\" if grammatical_correctness == 1 else \"Incorrect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96d8584e-5982-4b23-93d8-4a6c03095f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n",
      "     ---------------------------------------- 0.0/134.8 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/134.8 kB ? eta -:--:--\n",
      "     -------------------------------------- 134.8/134.8 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\anjan\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\anjan\\anaconda3\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\anjan\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anjan\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\anjan\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\anjan\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\anjan\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Downloading tokenizers-0.15.2-cp311-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\anjan\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\anjan\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\anjan\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\anjan\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anjan\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anjan\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anjan\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anjan\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Downloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
      "   ---------------------------------------- 0.0/8.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/8.8 MB 3.3 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.2/8.8 MB 3.5 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.4/8.8 MB 3.5 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.6/8.8 MB 3.9 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.8/8.8 MB 4.3 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.9/8.8 MB 4.1 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.9/8.8 MB 3.5 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.9/8.8 MB 3.3 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.9/8.8 MB 3.3 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.9/8.8 MB 3.3 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.0/8.8 MB 2.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.0/8.8 MB 2.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.0/8.8 MB 2.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.0/8.8 MB 2.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.0/8.8 MB 2.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.0/8.8 MB 2.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.0/8.8 MB 1.4 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.0/8.8 MB 1.4 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.0/8.8 MB 1.4 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.0/8.8 MB 1.3 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.0/8.8 MB 1.3 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.0/8.8 MB 1.1 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.0/8.8 MB 1.1 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.0/8.8 MB 1.1 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.1/8.8 MB 1.0 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.1/8.8 MB 1.1 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.3/8.8 MB 1.2 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 1.6/8.8 MB 1.3 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 1.7/8.8 MB 1.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.8/8.8 MB 1.5 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.8/8.8 MB 1.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.9/8.8 MB 1.5 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.9/8.8 MB 1.5 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.9/8.8 MB 1.5 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.0/8.8 MB 1.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.1/8.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.3/8.8 MB 1.5 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.4/8.8 MB 1.5 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.5/8.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 2.6/8.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 2.7/8.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 2.7/8.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 2.7/8.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 2.8/8.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 2.8/8.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 2.8/8.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 2.8/8.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 2.9/8.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.9/8.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.9/8.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.9/8.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.9/8.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.9/8.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 3.1/8.8 MB 1.4 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 3.1/8.8 MB 1.4 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 3.2/8.8 MB 1.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 3.3/8.8 MB 1.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 3.5/8.8 MB 1.4 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 3.6/8.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 3.8/8.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 3.9/8.8 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 4.1/8.8 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 4.3/8.8 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 4.4/8.8 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 4.6/8.8 MB 1.7 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 4.7/8.8 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 4.9/8.8 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.0/8.8 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.0/8.8 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.0/8.8 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.0/8.8 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.0/8.8 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.0/8.8 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.0/8.8 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.0/8.8 MB 1.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 5.1/8.8 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 5.3/8.8 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 5.5/8.8 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.6/8.8 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 5.7/8.8 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 5.9/8.8 MB 1.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.0/8.8 MB 1.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.0/8.8 MB 1.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.2/8.8 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 6.3/8.8 MB 1.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.5/8.8 MB 1.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.6/8.8 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 6.9/8.8 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.0/8.8 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.2/8.8 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.4/8.8 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.5/8.8 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.6/8.8 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.6/8.8 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.6/8.8 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.6/8.8 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.6/8.8 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.6/8.8 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.6/8.8 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.6/8.8 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.6/8.8 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.6/8.8 MB 1.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.7/8.8 MB 1.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.7/8.8 MB 1.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.7/8.8 MB 1.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.7/8.8 MB 1.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.7/8.8 MB 1.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.7/8.8 MB 1.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.7/8.8 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.8/8.8 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.8/8.8 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.8/8.8 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.8/8.8 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.8/8.8 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.8/8.8 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.8/8.8 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.8/8.8 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.8/8.8 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.8/8.8 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.8/8.8 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.8/8.8 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.8/8.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.9/8.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.0/8.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.0/8.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.1/8.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.3/8.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.3/8.8 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.5/8.8 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.6/8.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.8/8.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.8/8.8 MB 1.6 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.3-cp311-none-win_amd64.whl (287 kB)\n",
      "   ---------------------------------------- 0.0/287.3 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 122.9/287.3 kB 3.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 153.6/287.3 kB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  286.7/287.3 kB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 287.3/287.3 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.15.2-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/2.2 MB 4.3 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.3/2.2 MB 4.1 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.5/2.2 MB 4.2 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.5/2.2 MB 3.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.6/2.2 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.7/2.2 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.7/2.2 MB 2.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.8/2.2 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.8/2.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.9/2.2 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.1/2.2 MB 2.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.2/2.2 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.3/2.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 2.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.5/2.2 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.5/2.2 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.5/2.2 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.6/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.7/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.9/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.9/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.9/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.9/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.9/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.9/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.9/2.2 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.9/2.2 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.9/2.2 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.9/2.2 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.9/2.2 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.9/2.2 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.9/2.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.9/2.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.9/2.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.9/2.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.9/2.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.9/2.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.9/2.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.9/2.2 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.0/2.2 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.1/2.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 1.2 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, tokenizers, transformers\n",
      "Successfully installed safetensors-0.4.3 tokenizers-0.15.2 transformers-4.39.3\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59df2bb7-a1f7-4ddb-a899-a71e6d3dbf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12391f4ae03243b3ac379599f0984301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: [('The', 'DET'), ('quick', 'ADJ'), ('brown', 'ADJ'), ('fox', 'NOUN'), ('jumps', 'VERB'), ('over', 'ADP'), ('the', 'DET'), ('lazy', 'ADJ'), ('dog', 'NOUN'), ('.', 'PUNCT')]\n",
      "Dependency Tree: [('The', 'fox', 'det'), ('quick', 'fox', 'amod'), ('brown', 'fox', 'amod'), ('fox', 'jumps', 'nsubj'), ('jumps', 'jumps', 'ROOT'), ('over', 'jumps', 'prep'), ('the', 'dog', 'det'), ('lazy', 'dog', 'amod'), ('dog', 'over', 'pobj'), ('.', 'jumps', 'punct')]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "distilbert-base-uncased-finetuned-grammar is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/distilbert-base-uncased-finetuned-grammar/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\hub.py:398\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[0;32m    399\u001b[0m         path_or_repo_id,\n\u001b[0;32m    400\u001b[0m         filename,\n\u001b[0;32m    401\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[0;32m    402\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[0;32m    403\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    404\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m    405\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[0;32m    406\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m    407\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    408\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[0;32m    409\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m    410\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    411\u001b[0m     )\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1403\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, headers, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[0;32m   1401\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[0;32m   1402\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[1;32m-> 1403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[0;32m   1404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1405\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1261\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, headers, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1261\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m get_hf_file_metadata(\n\u001b[0;32m   1262\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   1263\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   1264\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m   1265\u001b[0m         timeout\u001b[38;5;241m=\u001b[39metag_timeout,\n\u001b[0;32m   1266\u001b[0m         library_name\u001b[38;5;241m=\u001b[39mlibrary_name,\n\u001b[0;32m   1267\u001b[0m         library_version\u001b[38;5;241m=\u001b[39mlibrary_version,\n\u001b[0;32m   1268\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[0;32m   1269\u001b[0m     )\n\u001b[0;32m   1270\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[0;32m   1271\u001b[0m     \u001b[38;5;66;03m# Cache the non-existence of the file and raise\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1674\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[0;32m   1673\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[1;32m-> 1674\u001b[0m r \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m   1675\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1676\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   1677\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m   1678\u001b[0m     allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1679\u001b[0m     follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1680\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m   1681\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m   1682\u001b[0m )\n\u001b[0;32m   1683\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:369\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[1;32m--> 369\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m    370\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    371\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    372\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    373\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    374\u001b[0m     )\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:393\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    392\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m--> 393\u001b[0m hf_raise_for_status(response)\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_errors.py:352\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    344\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    345\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    346\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    351\u001b[0m     )\n\u001b[1;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-661fa3f0-2c50d1b00f61906f484b1d71;dac5a640-cd87-4f4b-b524-cce32a3bc3b5)\n\nRepository Not Found for url: https://huggingface.co/distilbert-base-uncased-finetuned-grammar/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDependency Tree:\u001b[39m\u001b[38;5;124m\"\u001b[39m, dependency_tree)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Grammatical correctness prediction\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m grammatical_correctness \u001b[38;5;241m=\u001b[39m predict_grammatical_correctness(input_sentence)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrammatical Correctness:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grammatical_correctness)\n",
      "Cell \u001b[1;32mIn[8], line 18\u001b[0m, in \u001b[0;36mpredict_grammatical_correctness\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_grammatical_correctness\u001b[39m(sentence):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Load the pre-trained language model\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m     grammaticality_classifier \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistilbert-base-uncased-finetuned-grammar\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Make a prediction using the language model\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     result \u001b[38;5;241m=\u001b[39m grammaticality_classifier(sentence)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:779\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    775\u001b[0m     pretrained_model_name_or_path \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig) \u001b[38;5;129;01mand\u001b[39;00m pretrained_model_name_or_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[1;32m--> 779\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[0;32m    780\u001b[0m         pretrained_model_name_or_path,\n\u001b[0;32m    781\u001b[0m         CONFIG_NAME,\n\u001b[0;32m    782\u001b[0m         _raise_exceptions_for_gated_repo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    783\u001b[0m         _raise_exceptions_for_missing_entries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    784\u001b[0m         _raise_exceptions_for_connection_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[0;32m    786\u001b[0m     )\n\u001b[0;32m    787\u001b[0m     hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\hub.py:421\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    422\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    425\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    426\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    429\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    430\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    431\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    432\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: distilbert-base-uncased-finetuned-grammar is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from transformers import pipeline\n",
    "\n",
    "def get_pos_tags(sentence):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(sentence)\n",
    "    pos_tags = [(token.text, token.pos_) for token in doc]\n",
    "    return pos_tags\n",
    "\n",
    "def dependency_parse(sentence):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(sentence)\n",
    "    dependency_tree = [(token.text, token.head.text, token.dep_) for token in doc]\n",
    "    return dependency_tree\n",
    "\n",
    "def predict_grammatical_correctness(sentence):\n",
    "    # Load the pre-trained language model\n",
    "    grammaticality_classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-grammar\")\n",
    "\n",
    "    # Make a prediction using the language model\n",
    "    result = grammaticality_classifier(sentence)\n",
    "    grammatical_score = result[0][\"score\"]\n",
    "\n",
    "    # Use a logistic regression classifier to refine the prediction\n",
    "    # (assuming you have trained the classifier on a labeled dataset)\n",
    "    tokens = sentence.split()\n",
    "    features = [len(tokens), len(set(tokens)), sum(len(word) for word in tokens)]\n",
    "    X_train = [[5, 5, 20], [10, 8, 50], [3, 3, 15], [7, 6, 35]]  # Example training data\n",
    "    y_train = [1, 1, 0, 1]  # Example labels (1 for grammatically correct, 0 for incorrect)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    prediction = model.predict([features])[0]\n",
    "\n",
    "    # Combine the language model and logistic regression predictions\n",
    "    if grammatical_score > 0.5 and prediction == 1:\n",
    "        return \"Correct\"\n",
    "    else:\n",
    "        return \"Incorrect\"\n",
    "\n",
    "# Example usage\n",
    "input_sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# POS tagging\n",
    "pos_tags = get_pos_tags(input_sentence)\n",
    "print(\"POS Tags:\", pos_tags)\n",
    "\n",
    "# Dependency parsing\n",
    "dependency_tree = dependency_parse(input_sentence)\n",
    "print(\"Dependency Tree:\", dependency_tree)\n",
    "\n",
    "# Grammatical correctness prediction\n",
    "grammatical_correctness = predict_grammatical_correctness(input_sentence)\n",
    "print(\"Grammatical Correctness:\", grammatical_correctness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086310e0-38ca-46e7-aca3-0b9386550280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
